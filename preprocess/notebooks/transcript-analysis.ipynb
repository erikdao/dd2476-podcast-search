{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noble-german",
   "metadata": {},
   "source": [
    "# Transcript Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "forty-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data', 'podcasts-transcript', 'spotify-podcasts-2020')\n",
    "TRANSCRIPT_ROOT_DIR = os.path.join(DATA_DIR, 'podcasts-transcripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "prescribed-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(DATA_DIR, 'file_list.txt'), 'r') as f:\n",
    "#     first_line = next(f)\n",
    "\n",
    "# print(first_line)\n",
    "first_line = './podcasts-transcripts/4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2i074A63WWvH4Vc279IQiX.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-boards",
   "metadata": {},
   "source": [
    "Pick a sample transcript JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "welsh-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PATH = os.path.join(DATA_DIR, first_line[2:].replace(\"\\n\", ''))\n",
    "\n",
    "with open(SAMPLE_PATH, 'r') as f:\n",
    "    data = json.load(f)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "original-childhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternatives = data['results'][0]['alternatives']\n",
    "alternatives[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-whole",
   "metadata": {},
   "source": [
    "## Structure of the transcript JSON file\n",
    "\n",
    "* The file is a dict contianing a single key `results`, which is a list of items\n",
    "* Each item in the list is a dictionary that has only one key `alternatives`\n",
    "* This `alternatives` key refer to a list of **alternative** objects\n",
    "* Each **alternative** is a dict whose keys include `transcript`, `confidence`, `words`\n",
    "* `transcript`: an piece of texts corrresponding to a small portion of the transcript of each episode\n",
    "* `confidence`: double\n",
    "* `words`: a list of word token objects, each object has attributes `startTime`, `endTime` and `word`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-wichita",
   "metadata": {},
   "source": [
    "Structure of the transcript JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "protective-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = data['results']\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-library",
   "metadata": {},
   "source": [
    "### 1. A `result` item\n",
    "\n",
    "Each `result` item contains a single key called `alternatives` which is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "appointed-democrat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alternatives'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = results[0]\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-factory",
   "metadata": {},
   "source": [
    "### 2. An `alternative` item\n",
    "\n",
    "Each `alternative` item is dictionary containing three keys\n",
    "* `transcript`: an excerpt of the transcript\n",
    "* `confidence`: confidence of the transcript (I guess it indicates how accurate the generated texts are)\n",
    "* `words`: a list of JSON objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pending-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternatives = result['alternatives']\n",
    "len(alternatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coupled-panama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternative = alternatives[0]\n",
    "alternative.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beneficial-integration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello and welcome to the first episode of The Fan into flame podcast the official podcast of Greenwood Mennonite School athletics. My name is Tyler warfel. I teach high school math here at GMS and Coach the High School boys basketball team. I'm a big podcast listener. I listen to a lot of different types of podcasts mostly Sports podcast, but also some teaching podcast some news and current events podcasts. I like True Crime podcasts.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternative['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "burning-rhythm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853115439414978"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternative['confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "crude-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alternative['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-procedure",
   "metadata": {},
   "source": [
    "### 3. A `word` item\n",
    "\n",
    "Each word item is dict containing 3 required keys `startTime`, `endTime` and `word`. In some alternatives, a word can also contain the `speakerTag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "documentary-factory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'startTime': '1.400s', 'endTime': '1.700s', 'word': 'Hello'},\n",
       " {'startTime': '1.700s', 'endTime': '1.800s', 'word': 'and'},\n",
       " {'startTime': '1.800s', 'endTime': '2.200s', 'word': 'welcome'},\n",
       " {'startTime': '2.200s', 'endTime': '2.400s', 'word': 'to'},\n",
       " {'startTime': '2.400s', 'endTime': '2.400s', 'word': 'the'},\n",
       " {'startTime': '2.400s', 'endTime': '2.800s', 'word': 'first'},\n",
       " {'startTime': '2.800s', 'endTime': '3.500s', 'word': 'episode'},\n",
       " {'startTime': '3.500s', 'endTime': '3.600s', 'word': 'of'},\n",
       " {'startTime': '3.600s', 'endTime': '3.800s', 'word': 'The'},\n",
       " {'startTime': '3.800s', 'endTime': '4.300s', 'word': 'Fan'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternative['words'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-branch",
   "metadata": {},
   "source": [
    "## Anomaly detection\n",
    "\n",
    "We suspect that not all **alternatives** have the above structure, let's see if there is something weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "palestinian-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_al_results = [res for res in results if len(res['alternatives']) != 1]\n",
    "multi_al_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "earned-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_alternatives = [res['alternatives'][0] for res in results]\n",
    "len(res_alternatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "banned-royalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative doesn't have `transcript` key\n",
      "No. of words:  1283\n"
     ]
    }
   ],
   "source": [
    "for alt in res_alternatives:\n",
    "    if 'transcript' not in alt.keys():\n",
    "        print(\"Alternative doesn't have `transcript` key\")\n",
    "        print(\"No. of words: \", len(alt['words']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-height",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After the above exploratory analysis, we conclude that:\n",
    "* Each JSON transcript file hold a single dictionary that contains a single key `results`\n",
    "* The `results` is a list of dictionary that contains a single key `alternatives` which in tern is a list of object\n",
    "* Each `alternatives` contains a list of dictionary, dubbed `alternative`\n",
    "* There are **two** types of `alternative`:\n",
    "  - Type 1: a dictionary containing **three** keys: `transcript`, `confidence`, and `words`\n",
    "  - Type 2: a dictionary containing **only one** key `words` that hold all the word tokens in the transcript of a podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "encouraging-railway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of json file 67\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# for (dirpath, dirname, filenames) in os.walk(os.path.join(DATA_DIR, 'podcasts-transcripts')):\n",
    "#     print(dirname, filenames)\n",
    "#     count += 1\n",
    "#     if count > 100:\n",
    "#         break\n",
    "json_files = []\n",
    "PODCAST_DIR = os.path.join(DATA_DIR, 'podcasts-transcripts')\n",
    "for seg_name in os.listdir(PODCAST_DIR):  # Segments of transcript dataset\n",
    "    seg_path = os.path.join(PODCAST_DIR, seg_name)\n",
    "    for alpha_subdir in os.listdir(seg_path):  # alphabet subdirectory\n",
    "        alpha_subdir_path = os.path.join(seg_path, alpha_subdir)\n",
    "        for show_dir in os.listdir(alpha_subdir_path):  # show directory\n",
    "            if show_dir != 'show_4jJdofaAzXkKpsFJ8wGS9I':\n",
    "                continue\n",
    "            show_path = os.path.join(alpha_subdir_path, show_dir)\n",
    "            for fname in os.listdir(show_path):\n",
    "                if not fname.endswith(\".json\"):\n",
    "                    continue\n",
    "                json_files.append(os.path.join(seg_name, alpha_subdir, show_dir, fname))\n",
    "\n",
    "print(\"Number of json file\", len(json_files))\n",
    "\n",
    "# with open(os.path.join(DATA_DIR, \"json_file_list.txt\"), \"w\") as f:\n",
    "#     for json_file in json_files:\n",
    "#         f.write(json_file + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "distributed-reynolds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2i074A63WWvH4Vc279IQiX.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/0vyLvCgyBjcLeVJTKc2cUl.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/24d2AKEjyjZnsZBBo76h9U.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/0sM9AoMdEN0Xgiy5tToPrx.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/49qeJLT70g693viogUK4d0.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2KMSZ7uDnIpEywvssOuvez.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3oKCx45xRsHjzwbpKlIJd3.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/7jUE1DJ6xyxLBPMzSeLW5W.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3MEENb9JXqVd1Htm2tSNA2.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/6SqpthX1D3e1CXrCGgpSwi.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2SifBnEafsZhruD4mwKePQ.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2TWUNERicg9bMnHyq8dSr7.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4Qu1gLwPtCEuO6wWXXQ4CN.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2qoAP1EQlZyUq31uBaFM5b.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/71QbhzQw3yF5sJaJQyjhMY.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/6AmYkJtuvjIoudeF3hh8YL.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/1xgsssnaeQ8m3wgkO8Rue3.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/21Tyx8uOkFlDpRt6q3XxfP.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4HuifNYsOXKWxQ1rnqDzIQ.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4EVxPfdtaRZJmyHluABbmY.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/1z75l1YLZzVhdPLWe765NM.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4ZjDXyyIE7g1yeUAyY4RMj.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/0JXXR7iEnAkDvDXROfSwSE.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4vzYs3L6w25RXKTbjGDJt6.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/0GYWrKZWjUNaoAU0fkz36o.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4TiL3mxvHMgZWuJnAoZIUW.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2ebPLGX64i7FaIHsbjuK7s.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4ff808LI8AKSyhQYyglXrF.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2V4WclMp765mvncD7xiLYs.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3M7FDfpCBoXo3oLrwOQ3aY.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/1anx0R1RQzUPf9UZ2YJY5F.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/5FDMIG2qYbLaBQki5gQPbC.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3tuxaKigRvcXnFC9xeePGb.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4r4txosBdrnjrXPmN5iXip.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3iIyyeTU8lpDgsrm7d2u8w.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3PhVS0Wu4q3A3E5AiFYUbE.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2DxRdAE8VMfXxKFaxkjtBf.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2elnvsDO9RK0P1arl5v094.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3gOu1Y67Mc4Tf3GpXrvgyf.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3Hq6fJIM19YffIlttSqt1c.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/0cFsH91jbERkl0bejuCRH8.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/0C3UicH5kRSjcK0jereMuw.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/6EIqzGOboikN1vZw6c1vzY.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/22WbuLaHwfYGtGa7hqyaH9.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/1tP4KUXGGFzaxdWSKKYmpB.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/0zndwjrLK4IrKYwpuh37Xj.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2uCWUtq7vRN8ADQRgWOMFF.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4INYP7A4PtlUCUUKo7dabb.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/6kOY2QOXeze3MCB4T1XgQz.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/5jomIQOPgyx7DXm6H5HJa2.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2spo5mmSgq5lMS6xZ0xvJ4.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/7BqMuxY3BVjDhVArAemWYQ.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/1U8Be4p3EUmIXdNDSsckxF.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/77p7mMItonQVMu4qYug5kT.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2f5u6Kw7XdgRWPCV0scRf5.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3IxdHSrWSrHMtxZyqTwyRx.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2mFHiPGOibTiBpekp4ztwS.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3DVSq3XU7o0976e7EZQruT.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3Rpd85AJZAcN7RITkKQNXi.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/6iddkKhUArwKmX3LZnWDB8.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/0No8QfYGVeMO3IiV52aMy9.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2buUNsCXoII356ATsiAFX3.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4RGWarF0Kyy7nGctUwVJuu.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/4uUeMzZqCIQekTAtosaijJ.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/3vyRF3tCyXmJT9n6qMqXLZ.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/79sNG9EW5qFfDUF4ikPPeo.json',\n",
       " '4/J/show_4jJdofaAzXkKpsFJ8wGS9I/1c1cGrtdcVYxfXtTlM6dJG.json']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
