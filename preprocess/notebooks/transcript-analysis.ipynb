{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacterial-density",
   "metadata": {},
   "source": [
    "# Transcript Data Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sticky-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "competitive-danger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: /home/erik/Projects/KTH/dd2476-podcast-search\n",
      "DATA_DIR: /home/erik/Projects/KTH/dd2476-podcast-search/data/podcasts-transcript/spotify-podcasts-2020\n",
      "TRANSCRIPT_ROOT_DIR: /home/erik/Projects/KTH/dd2476-podcast-search/data/podcasts-transcript/spotify-podcasts-2020/podcasts-transcripts\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(f\"ROOT_DIR: {ROOT_DIR}\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data', 'podcasts-transcript', 'spotify-podcasts-2020')\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "TRANSCRIPT_ROOT_DIR = os.path.join(DATA_DIR, 'podcasts-transcripts')\n",
    "print(f\"TRANSCRIPT_ROOT_DIR: {TRANSCRIPT_ROOT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'file_list.txt'), 'r') as f:\n",
    "    first_line = next(f)\n",
    "\n",
    "print(first_line)\n",
    "# first_line = './podcasts-transcripts/4/J/show_4jJdofaAzXkKpsFJ8wGS9I/2i074A63WWvH4Vc279IQiX.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-peoples",
   "metadata": {},
   "source": [
    "Pick a sample transcript JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PATH = os.path.join(DATA_DIR, first_line[2:].replace(\"\\n\", ''))\n",
    "\n",
    "with open(SAMPLE_PATH, 'r') as f:\n",
    "    data = json.load(f)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternatives = data['results'][0]['alternatives']\n",
    "alternatives[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-trust",
   "metadata": {},
   "source": [
    "## Structure of the transcript JSON file\n",
    "\n",
    "* The file is a dict contianing a single key `results`, which is a list of items\n",
    "* Each item in the list is a dictionary that has only one key `alternatives`\n",
    "* This `alternatives` key refer to a list of **alternative** objects\n",
    "* Each **alternative** is a dict whose keys include `transcript`, `confidence`, `words`\n",
    "* `transcript`: an piece of texts corrresponding to a small portion of the transcript of each episode\n",
    "* `confidence`: double\n",
    "* `words`: a list of word token objects, each object has attributes `startTime`, `endTime` and `word`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-nutrition",
   "metadata": {},
   "source": [
    "Structure of the transcript JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data['results']\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-answer",
   "metadata": {},
   "source": [
    "### 1. A `result` item\n",
    "\n",
    "Each `result` item contains a single key called `alternatives` which is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results[0]\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-collaboration",
   "metadata": {},
   "source": [
    "### 2. An `alternative` item\n",
    "\n",
    "Each `alternative` item is dictionary containing three keys\n",
    "* `transcript`: an excerpt of the transcript\n",
    "* `confidence`: confidence of the transcript (I guess it indicates how accurate the generated texts are)\n",
    "* `words`: a list of JSON objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternatives = result['alternatives']\n",
    "len(alternatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative = alternatives[0]\n",
    "alternative.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative['confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alternative['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-blood",
   "metadata": {},
   "source": [
    "### 3. A `word` item\n",
    "\n",
    "Each word item is dict containing 3 required keys `startTime`, `endTime` and `word`. In some alternatives, a word can also contain the `speakerTag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative['words'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-hostel",
   "metadata": {},
   "source": [
    "## Anomaly detection\n",
    "\n",
    "We suspect that not all **alternatives** have the above structure, let's see if there is something weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_al_results = [res for res in results if len(res['alternatives']) != 1]\n",
    "multi_al_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_alternatives = [res['alternatives'][0] for res in results]\n",
    "len(res_alternatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alt in res_alternatives:\n",
    "    if 'transcript' not in alt.keys():\n",
    "        print(\"Alternative doesn't have `transcript` key\")\n",
    "        print(\"No. of words: \", len(alt['words']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-sleeve",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After the above exploratory analysis, we conclude that:\n",
    "* Each JSON transcript file hold a single dictionary that contains a single key `results`\n",
    "* The `results` is a list of dictionary that contains a single key `alternatives` which in tern is a list of object\n",
    "* Each `alternatives` contains a list of dictionary, dubbed `alternative`\n",
    "* There are **two** types of `alternative`:\n",
    "  - Type 1: a dictionary containing **three** keys: `transcript`, `confidence`, and `words`\n",
    "  - Type 2: a dictionary containing **only one** key `words` that hold all the word tokens in the transcript of a podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "# for (dirpath, dirname, filenames) in os.walk(os.path.join(DATA_DIR, 'podcasts-transcripts')):\n",
    "#     print(dirname, filenames)\n",
    "#     count += 1\n",
    "#     if count > 100:\n",
    "#         break\n",
    "json_files = []\n",
    "PODCAST_DIR = os.path.join(DATA_DIR, 'podcasts-transcripts')\n",
    "for seg_name in os.listdir(PODCAST_DIR):  # Segments of transcript dataset\n",
    "    seg_path = os.path.join(PODCAST_DIR, seg_name)\n",
    "    for alpha_subdir in os.listdir(seg_path):  # alphabet subdirectory\n",
    "        alpha_subdir_path = os.path.join(seg_path, alpha_subdir)\n",
    "        for show_dir in os.listdir(alpha_subdir_path):  # show directory\n",
    "            if show_dir != 'show_0XDDRp9nP5S3kgx413Ixg3':\n",
    "                continue\n",
    "            show_path = os.path.join(alpha_subdir_path, show_dir)\n",
    "            for fname in os.listdir(show_path):\n",
    "                if not fname.endswith(\".json\"):\n",
    "                    continue\n",
    "                json_files.append(os.path.join(seg_name, alpha_subdir, show_dir, fname))\n",
    "\n",
    "print(\"Number of json file\", len(json_files))\n",
    "\n",
    "# with open(os.path.join(DATA_DIR, \"json_file_list.txt\"), \"w\") as f:\n",
    "#     for json_file in json_files:\n",
    "#         f.write(json_file + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(json_files)\n",
    "json_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-coordinate",
   "metadata": {},
   "source": [
    "## Analyze a sample show id=`0XDDRp9nP5S3kgx413Ixg3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_id = '0XDDRp9nP5S3kgx413Ixg3'\n",
    "show_prefix = 'show_' + show_id\n",
    "show_dir = os.path.join(DATA_DIR, 'podcasts-transcripts/0/X/show_0XDDRp9nP5S3kgx413Ixg3')\n",
    "fnames = [fn for fn in os.listdir(show_dir) if fn.endswith(\".json\")]\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(fpath: str) -> typing.Any:\n",
    "    with open(fpath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def is_empty_alternative(alternatives: typing.List[typing.Any]) -> bool:\n",
    "    \"\"\"Check whether an `alternatives` list is empty\n",
    "    It's empty if it contains a single dictionary\n",
    "    \"\"\"\n",
    "    if len(alternatives) != 1:\n",
    "        return False\n",
    "    \n",
    "    return not bool(alternatives[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-interpretation",
   "metadata": {},
   "source": [
    "### Sample episode: id = `1qgr1zTevH7IOvK4My30ht`\n",
    "\n",
    "Episode 70: Make Your Opponent Hit a First Volley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_id = '1qgr1zTevH7IOvK4My30ht'\n",
    "episode_path = os.path.join(show_dir, episode_id + '.json')\n",
    "\n",
    "episode = read_json_file(episode_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_show_json_list = []\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'file_list.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        if show_prefix in line.strip():\n",
    "            sample_show_json_list.append(line.strip())\n",
    "len(sample_show_json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode['results'][0]['alternatives'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_id = '2GW6G1xC9RT4eUDuLgZMB5'\n",
    "episode_path = os.path.join(show_dir, episode_id + '.json')\n",
    "\n",
    "episode = read_json_file(episode_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode['results'][0]['alternatives'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
