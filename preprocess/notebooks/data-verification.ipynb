{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "closing-leather",
   "metadata": {},
   "source": [
    "# Data Verification\n",
    "\n",
    "While importing the transcript data from JSON to the database as well as elasticsearch, we've found out that there are quite many episodes that have the exact same transcripts.\n",
    "We're suspecting it's the error from the data. However, we create this notebook for verification.\n",
    "\n",
    "To that end, we perform the following steps from scratch:\n",
    "* We downloaded a fresh copy of the original dataset (i.e., `podcasts-no-audio-13GB.zip`)\n",
    "* We decompressed the `zip` file\n",
    "* There are three main `tar` files that contains the set of transcript json files\n",
    "* We created 3 separate folders `part0to2`, `part3to5`, `part6to7` and decompress those `tar` files into the corresponding folder. This is to avoid the potential overlapse of data into those `tar` files.\n",
    "\n",
    "The analysis on this notebook is conducted based on the folder structure resulted from the above steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "shared-radical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: /home/erik/Projects/KTH/dd2476-podcast-search\n",
      "DATA_DIR: /home/erik/Projects/KTH/dd2476-podcast-search/data/podcasts-transcript\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import typing\n",
    "from glob import glob\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(f\"ROOT_DIR: {ROOT_DIR}\")\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data', 'podcasts-transcript')\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "DATA_PREFIX = os.path.join(\"spotify-podcasts-2020\", \"podcasts-transcripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-population",
   "metadata": {},
   "source": [
    "**List all files in the part folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "potential-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "part0to2_path = os.path.join(DATA_DIR, \"part0to2\", DATA_PREFIX)\n",
    "part0to2 = [y for x in os.walk(part0to2_path) for y in glob(os.path.join(x[0], '*.json'))]\n",
    "\n",
    "part3to5_path = os.path.join(DATA_DIR, \"part3to5\", DATA_PREFIX)\n",
    "part3to5 = [y for x in os.walk(part3to5_path) for y in glob(os.path.join(x[0], '*.json'))]\n",
    "\n",
    "part6to7_path = os.path.join(DATA_DIR, \"part6to7\", DATA_PREFIX)\n",
    "part6to7 = [y for x in os.walk(part6to7_path) for y in glob(os.path.join(x[0], '*.json'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exotic-hindu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in list  105360\n",
      "Number of files in set  105360\n"
     ]
    }
   ],
   "source": [
    "file_list = part0to2 + part3to5 + part6to7\n",
    "print(\"Number of files in list \", len(file_list))\n",
    "\n",
    "file_set = set(file_list)\n",
    "print(\"Number of files in set \", len(file_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "painted-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105360 105360\n"
     ]
    }
   ],
   "source": [
    "json_files = [f.split(\"/\")[-1] for f in file_list]\n",
    "print(len(json_files), len(set(json_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-palace",
   "metadata": {},
   "source": [
    "### As we can see, there is no two json files with the same name, each file contains the transcript for each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-sphere",
   "metadata": {},
   "source": [
    "**Inspect show id=`0XDDRp9nP5S3kgx413Ixg3`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "wound-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "show_id = '4j5clif9VEUY2iFGzAaEDe'\n",
    "ep_list = [f for f in file_list if show_id in f]\n",
    "print(len(ep_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "noticed-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_episode_transcript(fpath: str) -> typing.Tuple[int, str]:\n",
    "    with open(fpath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = data['results']\n",
    "    transcripts = []\n",
    "    for res in results:\n",
    "        alternatives = res.get('alternatives')\n",
    "        if len(alternatives) != 1:\n",
    "            print(\"More than 1 alternative found\")\n",
    "        alternative = alternatives[0]\n",
    "        if not bool(alternatives):\n",
    "            continue\n",
    "\n",
    "        if 'transcript' in alternative.keys():\n",
    "            transcripts.append(alternative.get('transcript'))\n",
    "    return len(transcripts), \"\".join(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "oriented-rating",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/erik/Projects/KTH/dd2476-podcast-search/data/podcasts-transcript/part3to5/spotify-podcasts-2020/podcasts-transcripts/4/J/show_4j5clif9VEUY2iFGzAaEDe/6ZpoMAnKIzs7BUlAevP22p.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-37943c61ae4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_episode_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-96967d2b72ce>\u001b[0m in \u001b[0;36mload_episode_transcript\u001b[0;34m(fpath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_episode_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/erik/Projects/KTH/dd2476-podcast-search/data/podcasts-transcript/part3to5/spotify-podcasts-2020/podcasts-transcripts/4/J/show_4j5clif9VEUY2iFGzAaEDe/6ZpoMAnKIzs7BUlAevP22p.json'"
     ]
    }
   ],
   "source": [
    "count, transcript = load_episode_transcript(ep_list[0])\n",
    "print(count, transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-wildlife",
   "metadata": {},
   "source": [
    "**Separate part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "united-apollo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105360"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(DATA_DIR, DATA_PREFIX)\n",
    "json_file_list = [y for x in os.walk(data_path) for y in glob(os.path.join(x[0], '*.json'))]\n",
    "len(json_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "radical-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_list = [f.replace(data_path + \"/\", \"\") for f in json_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "square-lawyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4/J/show_4Jocfk9mf9D876514gZHet/03R2P2RnGOOZ57hGoXAT6z.json'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "executed-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, \"spotify-podcasts-2020\", \"json_file_list.txt\"), \"w\") as f:\n",
    "    for jf in json_file_list:\n",
    "        f.write(jf + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
